
<img width="720" height="405" alt="졸업과제메인" src="https://github.com/user-attachments/assets/2038a387-4857-4045-8751-f9bcc98dbce7" />


# 청각 제약 상황을 위한 실내 소리 인식 및 상황 감지 시스템

### 1. 프로젝트 배경
#### 1.1. 국내외 시장 현황 및 문제점

본 연구가 속한 돌봄 로봇(Care Robot) 및 가정용 로봇 시장은 이미 국내외에서 빠르게 성장하고 있다. 특히 고령화 사회 진입과 청각, 인지적 제약을 가진 인구 증가로 인해 돌봄 로봇의 필요성은 사회적 수요와 함께 급격히 증가하고 있다. 국내 시장의 경우, 연구개발특구진흥재단에 따르면 2024년 약 1,150억 원 규모로 추정되며, 2027년에는 약 두 배인 2,200억 원에 이를 것으로 전망된다. 연평균 성장률은 약 24.5%로, 이는 미국 전기차 시장(25.4%) 및 글로벌 AI 반도체 시장(21.6%)과 비슷하거나 더 높은 수준이다.

<img width="800" height="703" alt="image" src="https://github.com/user-attachments/assets/720afff4-aa77-4588-b21f-dc4428fe1072" />

*그림 1 돌봄 로봇 국내 시장 규모 및 전망*  

글로벌 시장 역시 빠르게 성장하고 있다. 시장조사기관 비즈니스 리서치 컴퍼니에 따르면 세계 돌봄 로봇 시장 규모는 2024년 29억8000만 달러(약 4조1000억 원)에서 매년 16.5%씩 성장해 2029년 64억3000만 달러(약 8조8348억 원)에 달할 것으로 전망됐다. 또한 글로벌 가정용 로봇 시장은 2023년 100억 달러(약 13.8조 원)에서 2032년 530억 달러(약 73조 원)로 성장할 것으로 전망된다. 특히 최근 삼성전자의 가정용 AI 로봇 ‘볼리(Ballie)’와 LG전자의 가정용 로봇 ‘Q9’이 출시되면서, 글로벌 대기업의 본격적인 시장 진입이 이루어지고 있다. 이는 가정용 로봇 시장이 이미 상용화 단계로 접어들었음을 보여준다.

이렇듯 돌봄 로봇 분야는 국내외에서 활발히 연구, 상용화되고 있으나 현재까지는 정서 교감, 건강 모니터링, 보행 보조 등 시각, 동작, 생체 데이터 중심의 기능에 집중되어 있다. 반면 청각 정보 취약 계층을 대상으로 한 소리 기반 안전 기능을 결합한 돌봄 로봇은 존재하지 않는다.

이는 고령층 및 청각장애인에게 특히 치명적인 공백이다. 현대 사회에서는 초인종, 가전기기 알림음, 경보음 등 다양한 소리를 통해 중요한 정보가 전달되는데, 청각 제약 상황에 놓인 사람들은 이를 실시간으로 인지하기 어렵다. 그 결과 화재·낙상·침입과 같은 위급 상황에서 신속한 대처가 지연되거나, 일상 속 방문자 호출 및 가전기기 알림을 놓쳐 생활의 질이 저하되는 문제가 발생한다.

현재 상용되는 제품의 경우 일부 경보음에 한정되거나 단순 시각 알림에 머무르는 경우가 많다. 실제 생활 환경에서 발생하는 다양한 소리를 인식하고 상황별로 대응하기에는 한계가 존재한다. 예를 들어, 단순히 소리를 감지하는 수준의 시스템은 소리의 종류나 발생 위치를 구분하지 못해 사용자가 어떤 상황인지 즉시 파악하기 어렵고, 보호자와의 정보 공유 기능도 부족하다.
이에 본 연구는 음원 분리 기반 소리 인식 기술과 SLAM 기반 로봇 시스템을 제안한다. 로봇은 SLAM을 통해 실내 환경과 사용자의 위치를 인식하며, 다양한 생활 소리를 실시간으로 분류해 위험·주의·도움의 세 단계로 전달한다. 특히, 소리 발생 여부와 종류는 로봇의 LED 색상 변화를 통해 직관적으로 사용자에게 전달되고, 동시에 스마트폰 푸시 알림을 통해 사용자와 보호자 모두가 실시간으로 상황을 인지할 수 있다. 이를 통해 사용자는 생활 속 다양한 소리에 효과적으로 대응할 수 있으며, 보호자는 원격으로 상황을 확인할 수 있어 안전성과 신뢰성이 크게 향상된다.



#### 1.2. 필요성과 기대효과

청각장애인들은 소리를 제대로 감지하지 못하여 일상생활에서 위험과 불안, 불편함을 지속적으로 호소하고 있다. 특히 우리 사회는 초고령화가 빠르게 진행되고 있으며, 자연스러운 신체 기능의 손실로 청각장애 인구 또한 꾸준히 증가하고 있다. 실제로 국내 청각장애인은 약 46.1만 명으로, 2020년의 44.7만 명에 비해 증가한 규모이다. 이 중 80대 이상이 47.5%, 70대가 27.0%를 차지하여 초고령자의 비중이 매우 높음을 알 수 있다. 청각장애의 후천적 장애 발생 시기는 나이가 많을 수록 발생률이 높아짐에 따라 청각 장애의 수가 증가한다. 청각장애는 후천적으로 발생하는 경우가 많아 고령 인구가 늘어날수록 환자 수도 증가하는 추세이다. 이러한 통계는 고령화 사회에 대비하여 청각장애인을 위한 보조기기 연구·개발이 필요함을 보여준다. 

이러한 맥락에서 소리 기반 안전 기능을 결합한 돌봄 로봇의 도입은 고령화 사회가 직면한 문제를 완화하는 효과적인 대안이 될 수 있다. 
첫째, 독거노인 및 청각장애인과 같은 취약계층이 서비스를 이용함으로써 안전한 생활 환경을 보장받을 수 있다. 
둘째, 보호자와 기관은 로봇을 통해 위험 상황을 실시간으로 공유받아 신속한 대응이 가능해지며, 이는 곧 사회적 안전망 강화를 의미한다. 
셋째, 축적된 데이터는 보험사, 지자체, 복지기관 등에서 정책 수립과 맞춤형 서비스 개발에 활용되어 스마트 복지 사회로의 전환을 촉진할 수 있다. 나아가 돌봄 인력 부족 문제를 완화하고 고령층 삶의 질 향상과 가족·사회적 부담 경감이라는 가치를 실현할 수 있다.

### 2. 개발 목표
#### 2.1. 목표 및 세부 내용

로봇은 실내 공간에서 사용자를 추적하며 소리를 수집하고 LED 디스플레이를 통해 직관적인 알림을 제공하므로, 사용자가 별도의 웨어러블 기기를 착용하거나 휴대폰 화면을 확인할 수 없는 상황에서도 실시간으로 상황을 인지할 수 있다. 이를 통해 고정형 센서의 한계를 극복하고 다양한 생활 환경에 적용할 수 있는 확장성을 확보한다. 또한 청각장애인과 난청 고령층이 놓치기 쉬운 위급 소리를 시각·진동·텍스트와 같은 대체 감각으로 전달하여 청각적 한계를 보완한다. 더불어 로봇과 모바일 애플리케이션을 활용한 이중 알림 구조와 보호자 연동 기능을 제공해 긴급 상황에서 빠르고 정확한 대응이 가능하도록 안전성과 신뢰성을 확보한다. 아울러 소리의 종류, 발생 위치, 시간 정보를 기록하고 시각화함으로써 사용자 친화적인 경험을 제공하고 생활 속 편의성을 증대시킨다. 마지막으로, 초고령화 사회에서 안전망을 강화하고 보조공학 시장의 확장 가능성에 기여함으로써 사회적 가치를 창출하는 것을 목표로 한다.

#### 2.2. 기존 서비스 대비 차별성 
안드로이드에서 제공하는 소리 알림(Sound Notification) 기능은 안드로이드 접근성 서비스의 일환으로, 스마트폰 내장 마이크를 활용하여 특정 환경음을 감지하고 이를 사용자에게 시각적·촉각적 방식으로 전달하는 기능이다. 이 기능은 연기 및 화재 경보, 초인종, 아기 울음소리, 개 짖는 소리 등 미리 정의된 8가지 소리에 한정되어 있으며, 여러 소리가 중첩해서 들릴 경우에는 한 가지만 탐지할 수 있으며 감지된 알림은 해당 개인 단말기에서만 확인할 수 있다. 따라서 사용자는 휴대폰을 소리 감지에 적합한 위치에 두어야 하며, 공간이 넓거나 환경음이 복잡한 상황에서는 소리를 놓칠 가능성이 존재한다.

| 구분        | 안드로이드 소리 알림 기능   | 우리 서비스                  |
|-------------|-----------------------------|------------------------|
| 플랫폼      | 스마트폰 내장 마이크 기반   | 실내 로봇 플랫폼 기반  |
| 소리 인식 개수 | 8가지                        | 최대 527가지            |
| 상황 인지 수준 | 단순 소리 탐지                | 3단계로 분류            |
| 알림 범위   | 개인 단말기                  | 개인 + 보호자          |
| 알림 형태   | 스마트폰 알림                 | 스마트폰 + 로봇 LED 알림 |
| 사용 제약   | 휴대폰 위치 고정 필요        | 실내 한정              |

#### 2.3. 사회적 가치 도입 계획 
본 연구는 초고령화 사회와 청각장애 인구 증가라는 사회적 문제를 해결하는 동시에 공공성, 지속 가능성, 환경 보호의 세 가지 측면에서 기여할 수 있도록 설계하였다. 

	•	공공성: 청각 취약계층을 대상으로 한 접근성을 강화하고, 고령층의 안전한 생활을 지원한다.
	•	지속 가능성: 로봇 및 소리 인식 시스템을 오픈소스 기반으로 개발해 유지보수와 확장이 용이하도록 설계한다.
	•	환경 보호: 에너지 효율적인 하드웨어와 저전력 알고리즘을 적용해 친환경적 운영이 가능하도록 한다.

### 3. 시스템 설계
#### 3.1. 시스템 구성도
<img width="800" alt="시스템아키텍처" src="https://github.com/user-attachments/assets/c8371cb8-3f86-492e-b254-4ff49a166db4" />

*그림 2 시스템 아키텍처*

>
#### 3.2. 사용 기술

##### 운영체제 (OS)
| 이름     | 버전    | 사용 목적                  |
|----------|---------|----------------------------|
| Ubuntu   | 22.04   | ROS2 Humble 공식 지원 OS   |
| macOS    | Sequoia | iOS 애플리케이션 개발      |
| Windows  | 11      | 일반 사용자 테스트 환경    |

---

##### 프로그래밍 언어
| 이름   | 버전  | 사용 목적                      |
|--------|-------|--------------------------------|
| Swift  | 6.1.2 | iOS 애플리케이션 개발          |
| Python | 3.11  | FastAPI 및 데이터 처리         |
| C++    | 17    | ROS2 패키지 및 로봇 알고리즘 구현 |

---

##### 프레임워크 및 라이브러리
| 이름                       | 버전     | 사용 목적                                         |
|----------------------------|----------|--------------------------------------------------|
| SwiftUI                    | iOS18.5  | 모바일 앱 UI 개발                                |
| ROS2                       | Humble   | 로봇 자율주행 및 센서 데이터 처리                 |
| FastAPI                    | 0.115.12 | 서버 API 백엔드 구축                             |
| PyTorch                    | 2.5.1+cpu| 딥러닝 모델 실행 및 텐서 연산, STFT/ISTFT 변환, 신호 처리 |
| transformers (Huggingface) | 4.55.2   | AST 모델 특징추출, 오디오 분류                   |
| CocoaMQTT                  | 2.1.6    | iOS 클라이언트에서 MQTT 프로토콜을 통한 로봇 데이터 송수신 |
| Nav2                       | 1.1.18   | 로봇 경로 계획, 장애물 회피, 자율 주행 제어       |
| SLAM Toolbox               | 2.6.10   | 자율적 지도 생성, 위치 추정                      |
| paho-mqtt                  | 2.1.0    | 백엔드 서버에서 MQTT 메시지 송수신 처리           |

---

##### 데이터베이스
| 이름  | 버전 | 사용 목적                                  |
|-------|------|-------------------------------------------|
| MySQL | 8.0  | 사용자, 보호자, 소리 이벤트 등 데이터 저장 및 관리 |

---

##### 하드웨어
| 이름            | 모델명                        | 사용 목적              |
|-----------------|-------------------------------|------------------------|
| LiDAR          | MS200                         | 장애물 감지, 지도 생성 |
| 모터           | 310 메탈 인코더 모터          | 로봇 주행              |
| Mic Array      | ReSpeaker MicArray v2.0       | 소리 수집              |
| ESP32 프로세서 | ESP32-S3-WROOM-1U-N4R2        | 센서 데이터 처리       |

---

##### 개발 도구 및 배포 환경
| 구분             | 항목                           | 버전 / 세부 사항                          |
|------------------|--------------------------------|-------------------------------------------|
| IDE / 에디터     | Xcode                          | 26.0 beta 7                               |
|                  | Visual Studio Code             | 1.98.2 (Universal)                        |
|                  | PyCharm                        | 2025.2.1.1                                |
| 버전 관리        | GitHub                         | -                                         |
|                  | Git                            | 2.34.1                                    |
| 통신 / 네트워크  | MQTT                           | CocoaMQTT, EMQX                           |
|                  | RESTful API                    | -                                         |
| 시뮬레이션 / 시각화 | RViz2                        | 11.2.19-1jammy.20250729.022220            |
| 테스트 도구      | Postman                        | 10.7.1                                    |
| 배포 / 운영      | Docker                         | 27.0.3                                    |
|                  | Nginx                          | 1.25.3                                    |
|                  | Firebase Cloud Messaging (FCM) | 9.23.0                                    |
|                  | AWS EC2                        | Ubuntu 22.04.3 LTS                        |


### 4. 개발 결과
#### 4.1. 구현 기능

##### 4.1.1. 로봇 측 기능
- SLAM 기반 실내 지도 생성
- explore_lite 기반 자율 탐사
- 사용자 인식 및 추적
- 실시간 카메라 스트리밍
- LED 시각 알림 (위험/주의/도움 단계 구분)

##### 4.1.2. 소리 인식 및 분류 기능
- 마이크 어레이 기반 소리 수집
- 음원 분리 및 소리 분류 (위험·주의·도움 3단계)

##### 4.1.3. 알림 및 보호자 연동 기능
- 소리 발생 시 사용자 및 보호자 실시간 알림 전송
- 긴급 신고(119 문자 자동 생성)
- 보호자 호출 알림

##### 4.1.4. 애플리케이션 기능
- 사용자 분류 (사용자, 보호자)
- 소리 아카이빙 및 달력 기반 기록 조회
- 로봇 상태 모니터링 (배터리, 연결 여부)
- 계정 관리(로그아웃, 계정 삭제, 도움말 페이지)

##### 4.1.5. 시스템 안정성
- 네트워크 단절 시 로컬 LED 알림 유지
- 배터리 부족·통신 오류 시 시작 장소로 이동

#### 4.3. 디렉토리 구조
>
#### 4.4. 산업체 멘토링 의견 및 반영 사항

외부 전문가 자문을 통해 기술적 타당성과 사용자 친화성을 보완할 수 있는 다양한 조언을 받았다. 주요 의견은 다음과 같다.

##### 4.4.1. 음원분리 기반 소리 인식의 실시간성 한계
- 자문 의견 : DGMO 모델의 연산량으로 인해 실시간 처리 가능성이 낮을 수 있으므로, 경량화 기법 적용의 구체적인 실행 계획 필요
- 반영 방안 : 연산량이 많은 DGMO 모델을 실시간 처리에 더 적합한 경량 AST 모델로 교체하고, 목표 소리를 먼저 빠르게 분류한 뒤 해당 소리만 마스크 방식으로 분리하는 접근법을 적용하였다다. 이 방식은 전체 시스템의 연산량 줄여, 로봇의 제한된 하드웨어 자원 내에서도 실시간 응답을 가능하게 한다.

##### 4.4.2. SLAM Dense Map 변환 및 통합 과정에서의 리스크
- 자문 의견 : 통합 시 발생할 수 있는 성능 저하 및 누적 오차에 대한 보완책 요구
- 반영 방안 : 기존 Dense Map 변환 기반 접근을 LiDAR 센서를 활용한 SLAM으로 변경했다. LiDAR 기반 매핑은 깊이 추정 모델 대비 정확도와 안정성이 높아, 누적 오차를 줄이고 실시간 통합 과정에서의 성능 저하 문제를 완화할 수 있다.

##### 4.4.3. 성능 지표 부재
- 자문 의견 : 소리 인식 정확도, 응답 시간, 배터리 지속 시간과 같은 정량적 성능 목표를 수립하여 검증 필요
- 반영 방안 : 소리 인식 후 사용자 단말기에 알림이 도달하기까지의 전체 지연 시간을 측정하여 성능을 검증한다. 이를 위해 소리 발생 시각, 소리 분류 완료 시각, 서버 요청 시각, 푸시 알림 도착 시각을 각각 기록하고, 구간별 지연 시간과 총 소요 시간을 산출한다. 목표값은 8초 이내로 설정하며, 이는 인간의 평균 반응속도 및 안전 규격에서 제시하는 10초 이내 알림 기준을 고려한 것이다. 또한, 배터리 지속 시간은 연속 동작 시간을 기준으로 테스트하고, 소리 인식 정확도는 사전 정의된 다양한 음원(경보음, 생활 소리 등)에 대한 분류 결과와 실제 라벨을 비교하여 정량적으로 평가한다.

##### 4.4.4. 고령층 사용자를 고려한 초기 설정 단순화 필요성
- 자문 의견 : 얼굴 등록, Wi-Fi 연결 등 초기 설정 절차를 최대한 단순화하고 명확한 가이드 제공 필요
- 반영 방안 : 얼굴 등록 절차를 삭제하고 회원 가입 절차를 단순화 하였다. 사용자는 이름, 전화번호, 비밀번호, 비밀번호 확인, 생년월일 입력만으로도 가입이 가능하며 어려운 영문 아이디 대신 전화번호로 로그인할 수 있도록 했다. 앱 사용법을 쉽게 이해할 수 있도록 도움말 탭을 추가하여 사용자가 명확히 인지할 수 있도록 하였다.

##### 4.4.5. 네트워크 불안정 환경 대응 전략
- 자문 의견 : 네트워크 단절 시에도 기본적인 소리 인식 및 알림이 가능하도록 오프라인 모드 지원 필요
- 반영 방안 : 네트워크 단절 상황에서도 로컬 단말(Raspberry Pi 기반 로봇 본체)에서 기본적인 소리 인식과 LED 시각 알림을 지속 제공하도록 설계하였다.


### 5. 설치 및 실행 방법
>
#### 5.1. 설치절차 및 실행 방법
> 설치 명령어 및 준비 사항, 실행 명령어, 포트 정보 등


### 6. 소개 자료 및 시연 영상
#### 6.1. 프로젝트 소개 자료
> PPT 등
#### 6.2. 시연 영상
> 영상 링크 또는 주요 장면 설명

### 7. 팀 구성
#### 7.1. 팀원별 소개 및 역할 분담


<div>

| <img src="https://github.com/mingkyeongg.png" width="200px;" alt="이민경"/> | <img src="https://github.com/Bentlytrucker.png" width="200px;" alt="박지용"/> | <img src="https://github.com/mogld.png" width="200px;" alt="이진솔"/> |
| :------------------------------------------------------------------------: | :---------------------------------------------------------------------------: | :-------------------------------------------------------------------: |
| [**이민경**](https://github.com/mingkyeongg)                               | [**박지용**](https://github.com/Bentlytrucker)                               | [**이진솔**](https://github.com/mogld)                               |
| <img src="https://img.shields.io/badge/iOS_App_Dev-FF5733?style=flat&logo=swift" /> <br> <img src="https://img.shields.io/badge/Mobile_App-FF5733?style=flat&logo=apple" /> <br> <img src="https://img.shields.io/badge/System_Infra-6DB33F?style=flat&logo=docker" /> | <img src="https://img.shields.io/badge/AI_Model-yellow?style=flat&logo=pytorch" /> <br> <img src="https://img.shields.io/badge/SLAM-orange?style=flat&logo=ros" /> <br> <img src="https://img.shields.io/badge/Robot_Control-9cf?style=flat&logo=arduino" /> | <img src="https://img.shields.io/badge/Backend-0A66C2?style=flat&logo=fastapi" /> <br> <img src="https://img.shields.io/badge/Database-4479A1?style=flat&logo=mysql" /> <br> <img src="https://img.shields.io/badge/CI/CD-2088FF?style=flat&logo=githubactions" /> |
| - 주행 알고리즘 개발 <br> - iOS 애플리케이션 개발 <br> - 시스템 통신 인프라 구성 | - 사용자 인식 및 실내 소리 분류 AI 개발 <br> - 로봇 위치 추정 <br> - SLAM 구현 | - 백엔드 API 설계 <br> - DB 설계 및 연동 <br> - CI/CD 파이프라인 구축 |

</div>


#### 7.2. 팀원 별 참여 후기


<div>

| [이민경](https://github.com/mingkyeongg) | [박지용](https://github.com/Bentlytrucker) | [이진솔](https://github.com/mogld) |
|:----------------------------------------:|:------------------------------------------:|:----------------------------------:|
| 📱 **Mobile / Infra** <br> _"프로젝트 전반을 아우르며 다양한 기술 스택을 실제로 적용할 수 있는 소중한 경험이었습니다."_ | 🤖 **AI / SLAM** <br> _"이론으로만 배우던 로봇 알고리즘을 실제 환경에서 구현하며 많은 도전을 할 수 있었습니다."_ | 🛠️ **Backend / DB** <br> _"백엔드와 데이터베이스 설계를 통해 안정적인 시스템 운영의 중요성을 체감했습니다."_ |

</div>


### 8. 참고 문헌 및 출처

[1] World Health Organization, “WHO: 1 in 4 people projected to have hearing problems by 2050,” Mar. 2, 2021. [Online]. Available: https://www.who.int/news/item/02-03-2021-who-1-in-4-people-projected-to-have-hearing-problems-by-2050

[2] G. Lee, G. Han, and P. H. Seo, “DGMO: Training-Free Audio Source Separation through Diffusion-Guided Mask Optimization,” arXiv preprint arXiv:2506.02858, 2025, doi: 10.48550/arXiv.2506.02858.

[3] Y. Gong, Y.-A. Chung, and J. Glass, “AST: Audio Spectrogram Transformer,” in Proc. Interspeech, Brno, Czechia, Aug.–Sep. 2021, pp. 571–575, doi: 10.21437/Interspeech.2021-698.

[4] P. Aerts and E. Demeester, “Benchmarking of 2D-SLAM Algorithms: A Validation for the TETRA project Ad Usum Navigantium,” ACRO Research Group, KU Leuven, Dept. of Mechanical Engineering, Campus Diepenbeek, Belgium, Jul. 2017.

[5] K.-M. Lee, “A Study on the Reaction Time to Visual and Auditory Stimuli in Normal Korean Adults,” Journal of the Korean Academy of Rehabilitation Medicine, vol. 20, no. 3, pp. 483–489, 1996. (in Korean).
